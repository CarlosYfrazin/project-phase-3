
# Project_Phase3

## Objectif du projet
Ce projet a √©t√© r√©alis√© dans le cadre du cours de **Data Science & Intelligence Artificielle** (enseignant : *Wedter Jerome*).  
Il consiste √† d√©velopper un mod√®le de **classification supervis√©e** afin de pr√©dire le **d√©sabonnement (churn)** des clients de **SyriaTel**.  
L‚Äôobjectif est d‚Äôidentifier les clients √† risque et de proposer des strat√©gies de r√©tention adapt√©es pour am√©liorer la fid√©lisation.  

##  Contenu du d√©p√¥t
- `Project_Phase3.ipynb` ‚Üí Notebook principal avec le code, l‚Äôanalyse et les r√©sultats.  
- `data/bigml_59c28831336c6604c800002a.csv` ‚Üí Jeu de donn√©es client (3333 enregistrements, 21 variables).  
- `requirements.txt` ‚Üí Biblioth√®ques Python n√©cessaires.  

##  √âtapes principales
1. **Chargement et pr√©paration des donn√©es**
   - Nettoyage des colonnes, conversion de la variable cible `churn` en num√©rique.  
   - Encodage *One-Hot* des variables cat√©gorielles.  
   - Standardisation des variables num√©riques.  

2. **Mod√©lisation**
   - **R√©gression Logistique (baseline)** : mod√®le simple et interpr√©table, Accuracy ‚âà 86% mais faible recall sur les clients churn.  
   - **R√©gression Logistique optimis√©e (GridSearchCV)** : r√©glage d‚Äôhyperparam√®tres, peu d‚Äôam√©lioration sur le recall.  
   - **Random Forest (mod√®le final)** : meilleur compromis avec ROC-AUC = 0.847 et Recall = 0.600, ce qui permet d‚Äôidentifier davantage de clients √† risque.  

3. **√âvaluation des mod√®les**
   - Comparaison via Accuracy, ROC-AUC, Recall (classe churn) et F1-score.  
   - Visualisations : matrices de confusion et courbes ROC.  
   - Importance des variables pour mieux comprendre les facteurs influen√ßant le churn.  

##  R√©sultats principaux
- Logistic Regression Baseline ‚Üí Accuracy: 0.862 | ROC-AUC: 0.808 | Recall: 0.247 | F1: 0.343  
- Logistic Regression Optimis√©e ‚Üí Accuracy: 0.861 | ROC-AUC: 0.808 | Recall: 0.247 | F1: 0.340  
- Random Forest (final) ‚Üí Accuracy: 0.861 | ROC-AUC: 0.847 | Recall: 0.600 | F1: 0.556  


**Random Forest** est retenu comme mod√®le final gr√¢ce √† sa meilleure capacit√© √† d√©tecter les clients √† risque.  

## üí° Implications m√©tier
- Un **recall plus √©lev√©** permet d‚Äôidentifier davantage de clients susceptibles de se d√©sabonner.  
- Cela aide la direction marketing √† lancer des **actions de r√©tention cibl√©es** (offres personnalis√©es, appels sortants, suivi du service client).  
- Les variables cl√©s d√©tect√©es par le mod√®le :  
  - Nombre d‚Äôappels au service client  
  - Plan international  
  - Minutes de communication (day/evening/night)  

## üöÄ Prochaines √©tapes
- Approfondir l‚Äôoptimisation d‚Äôhyperparam√®tres (Random Forest, Gradient Boosting, XGBoost).  
- Tester le r√©√©quilibrage des classes (ex. SMOTE).  
- Ajuster les seuils de classification pour optimiser le compromis **precision vs recall**.  

## üë®‚Äçüéì Auteur
- **Carlos Yfrazin**  
√âtudiant en **Data Science & AI**
